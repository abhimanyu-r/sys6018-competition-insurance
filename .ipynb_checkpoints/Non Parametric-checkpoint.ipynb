{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Approach (Random Forests)\n",
    "\n",
    "Here we explore a python implementation of random forest for this competition. The reason for the transition to python was a computational one. R was proving to be far too slow to create even trivially sized forests. Python gives an increase in speed by nature, but also has more natural integration of parallel tree creation, allowing for the creation of larger forests. That being said, computation is still an issue and will come into play as we go through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Coefficient\n",
    "\n",
    "Code, adapted from the code on collab, to compute the gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unnormalized_gini_index(g, predicted_probabilities):\n",
    "  \n",
    "    if len(g) != len(predicted_probabilities):\n",
    "        print(\"Actual and Predicted need to be equal lengths!\")\n",
    "        return\n",
    "\n",
    "    # arrange data into table with columns of index, predicted values, and actual values\n",
    "    d = {\"truth\": g, \"pred\": predicted_probabilities}\n",
    "    gini_table = pd.DataFrame(data = d, index = range(1,len(g) + 1))\n",
    "\n",
    "    # sort rows in decreasing order of the predicted values, breaking ties according to the index\n",
    "    # gini_table = gini.table[order(-gini.table$predicted.probabilities, gini.table$index), ]\n",
    "    gini_table = gini_table.sort_values(\"pred\", ascending = False)\n",
    "\n",
    "    # get the per-row increment for positives accumulated by the model \n",
    "    num_ground_truth_positivies = sum(gini_table[\"truth\"])\n",
    "    model_percentage_positives_accumulated = gini_table[\"truth\"] / num_ground_truth_positivies\n",
    "\n",
    "    # get the per-row increment for positives accumulated by a random guess\n",
    "    random_guess_percentage_positives_accumulated = 1 / len(gini_table[\"truth\"])\n",
    "\n",
    "    # calculate gini index\n",
    "    gini_sum = np.cumsum(model_percentage_positives_accumulated - random_guess_percentage_positives_accumulated)\n",
    "    gini_index = sum(gini_sum) / len(gini_table[\"truth\"]) \n",
    "    return(gini_index)\n",
    "\n",
    "\n",
    "#' Calculates normalized Gini index from ground truth and predicted probabilities.\n",
    "#' @param ground.truth Ground-truth scalar values (e.g., 0 and 1)\n",
    "#' @param predicted.probabilities Predicted probabilities for the items listed in ground.truth\n",
    "#' @return Normalized Gini index, accounting for theoretical optimal.\n",
    "def normalized_gini_index(g, predicted_probabilities):\n",
    "    model_gini_index = unnormalized_gini_index(g, predicted_probabilities)\n",
    "    optimal_gini_index = unnormalized_gini_index(g, g)\n",
    "    return(model_gini_index / optimal_gini_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to just try and fit a random forest to the raw train data and get a baseline for the gini index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train[\"target\"]\n",
    "x = train.drop([\"id\", \"target\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 57)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, max_depth=2, random_state=0, n_jobs=-1, max_features=1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "ids = test[\"id\"]\n",
    "test = test.drop([\"id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(test)\n",
    "probs_final = [x[1] for x in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = {'id':ids, 'target':probs_final}\n",
    "result1_df = pd.DataFrame(data = result1)\n",
    "\n",
    "result1_df.to_csv(\"predictionsRF10-24-17.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gave a baseline score of  0.232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use OOB to look at the effect of the number of predictors considered for each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run OOB on number of features\n",
    "\n",
    "for i in [1, 10, 20, 30]:\n",
    "    \n",
    "    # Use max depth of 11 from cross validation done below\n",
    "    cl = RandomForestClassifier(n_estimators=500, max_depth=11, random_state=0, n_jobs=-1, max_features=i, oob_score=True)\n",
    "    cl = clf.fit(x, y)\n",
    "    print(str(i) + \" \" + str(model.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB Score for various sizes of features\n",
    "\n",
    "1: 0.96355248214081701\n",
    "\n",
    "10: 0.963542401699\n",
    "\n",
    "20: 0.963552482141\n",
    "\n",
    "30: 0.963545761846\n",
    "\n",
    "Number of features does not seem to make a huge difference, so we will stick with the baseline of log(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we get a sense of some of the important predictors. This is more or less exploratory. We will run a 3 fold cv and find what variables show up in in the top 20 most important predictors for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "y_kfold = np.array(train[\"target\"])\n",
    "x_kfold = np.array(train.drop([\"id\", \"target\"], axis = 1))\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "kf.get_n_splits(x_kfold, y_kfold)\n",
    "forest = ExtraTreesClassifier(n_estimators=500, max_depth=2, random_state=0, n_jobs=-1, max_features=\"log2\")\n",
    "\n",
    "ginis = []\n",
    "\n",
    "ratio = [0]*57\n",
    "\n",
    "for train_index, test_index in kf.split(x_kfold, y_kfold):\n",
    "    X_train, X_test = x_kfold[train_index], x_kfold[test_index]\n",
    "    y_train, y_test = y_kfold[train_index], y_kfold[test_index]\n",
    "    \n",
    "    model = forest.fit(X_train, y_train)\n",
    "    probs = forest.predict_proba(X_test)\n",
    "    probs_final = [x[1] for x in probs]\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    index = 0\n",
    "    for f in range(X_train.shape[1]):\n",
    "        # print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        if(index < 20):\n",
    "            ratio[indices[f]] += 1\n",
    "        index += 1\n",
    "\n",
    "    ginis.append(normalized_gini_index(g=y_test, predicted_probabilities=probs_final))\n",
    "    print(len(ginis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21582272536451991, 0.22396413793473299, 0.22061223708988106]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 34]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the cross validation Gini\n",
    "print(ginis)\n",
    "\n",
    "# Find which variables top level of important in all folds\n",
    "interest = [x for x in range(0,57) if ratio[x] > 2]\n",
    "interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives Gini scores of [0.21581968897515907, 0.22396513332529083, 0.22062593969640684]\n",
    "\n",
    "and important columns of [3, 4, 5, 6, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now dive into our actual cross validation. We will stick to 3-fold cross validation as opposed to OOB error just because this was the approach we took before learning about OOB and the results should be roughly the same. Plus, this will give us an idea of gini as opposed to accuracy. Further, we choose 3 fold as it showed to be the most computationally feasible. We will cross validate on both tree size and max depth of tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25916813682529266, 0.2643633991281692, 0.2615973871654434]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_kfold = np.array(train[\"target\"])\n",
    "x_kfold = np.array(train.drop([\"id\", \"target\"], axis = 1))\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "kf.get_n_splits(x_kfold, y_kfold)\n",
    "forest = RandomForestClassifier(n_estimators=500, max_depth=12, random_state=0, n_jobs=4, max_features=\"log2\")\n",
    "\n",
    "ginis = []\n",
    "index = 1\n",
    "for train_index, test_index in kf.split(x_kfold, y_kfold):\n",
    "    X_train, X_test = x_kfold[train_index], x_kfold[test_index]\n",
    "    y_train, y_test = y_kfold[train_index], y_kfold[test_index]\n",
    "    \n",
    "    model = forest.fit(X_train, y_train)\n",
    "    probs = forest.predict_proba(X_test)\n",
    "    probs_final = [x[1] for x in probs]\n",
    "    ginis.append(normalized_gini_index(g=y_test, predicted_probabilities=probs_final))\n",
    "    print(index)\n",
    "    index += 1\n",
    "    \n",
    "ginis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ginis for various tree sizes, 3 fold, max depth 2:\n",
    "\n",
    "n = 100  : [0.22831513135331596, 0.23864099086790785, 0.23103020976139921]\n",
    "\n",
    "n = 500  : [0.23399624333700408, 0.2411106344163601, 0.23516488700519048]\n",
    "\n",
    "n = 750  : [0.23386079491144549, 0.24087016368279662, 0.23520949462470858]\n",
    "\n",
    "n = 1000 : [0.23388456236128888, 0.24129153652280616, 0.23561118600698075]\n",
    "\n",
    "Tree size seems to have little effects, beyond 500, so we will use that and cross validate on the maximum depth of the tree.\n",
    "\n",
    "max depth = 3 : [0.24062733291355087, 0.24570173158111713, 0.24159062096266626]\n",
    "\n",
    "max depth = 4 : [0.2426543130398667, 0.25000749888491419, 0.24464726289094912]\n",
    "\n",
    "max depth = 5 : [0.24782642403706451, 0.25376128306085599, 0.2492086061125024]\n",
    "\n",
    "max depth = 6 : [0.25131812425267502, 0.25640949938610264, 0.25279046253967674]\n",
    "\n",
    "max depth = 7 : [0.2551048402902254, 0.26008715643937819, 0.25576034299523143]\n",
    "\n",
    "max depth = 8 : [0.25678261394094259, 0.2616982944395666, 0.25828227944175075]\n",
    "\n",
    "max depth = 9 : [0.25785094996229607, 0.26305865767777453, 0.25982247787905172]\n",
    "\n",
    "max depth = 10 : [0.26043552198432962, 0.26494932536341631, 0.26163287418190628]\n",
    "\n",
    "max depth = 11 : [0.26024302733938087, 0.266616577059546, 0.26264853956131246]\n",
    "\n",
    "max depth = 12 : [0.25916813682529266, 0.2643633991281692, 0.2615973871654434]\n",
    "\n",
    "Increasing depth does seem to have an effect, but it tapers off after 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Model on Raw Data (BEST MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what we have found, make a prediction tree using the raw, uncleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train[\"target\"]\n",
    "x = train.drop([\"id\", \"target\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best paramaters found using CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_test = RandomForestClassifier(n_estimators=500, max_depth=11, random_state=0, n_jobs=-1, max_features=\"log2\")\n",
    "clf_test.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "ids = test[\"id\"]\n",
    "test = test.drop([\"id\"], axis = 1)\n",
    "probs = clf_test.predict_proba(test)\n",
    "probs_final = [x[1] for x in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = {'id':ids, 'target':probs_final}\n",
    "result1_df = pd.DataFrame(data = result1)\n",
    "\n",
    "result1_df.to_csv(\"predictionsRF11-1-17.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** KAGGLE SCORE: 0.259 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun on clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try again but use the cleaned dataset with NA's imputed with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"clean_data_rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train[\"target\"]\n",
    "x = train.drop([\"id\", \"target\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=11, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=-1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test = RandomForestClassifier(n_estimators=500, max_depth=11, random_state=0, n_jobs=-1, max_features=\"log2\")\n",
    "clf_test.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "ids = test[\"id\"]\n",
    "test = test.loc[:, train.columns]\n",
    "test = test.drop([\"id\", \"target\"], axis = 1)\n",
    "probs = clf_test.predict_proba(test)\n",
    "probs_final = [x[1] for x in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = {'id':ids, 'target':probs_final}\n",
    "result1_df = pd.DataFrame(data = result1)\n",
    "\n",
    "result1_df.to_csv(\"predictionsRF11-1-17.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** KAGGLE SCORE: 0.250**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
